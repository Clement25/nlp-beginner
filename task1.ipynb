{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(93636,) (31212,) (31212,)\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_root = '/home/henry/nlp-beginner/data/'\n",
    "train_data=pd.read_csv(data_root+'train.tsv',sep='\\t')\n",
    "# test_data=pd.read_csv(data_root+'test.tsv',sep='\\t')\n",
    "pd.set_option('display.width', 900)\n",
    "x_all = train_data['Phrase']\n",
    "y_all = train_data['Sentiment']\n",
    "# test_x = test_data['Phrase']\n",
    "# test_y = test_data['Sentiment']\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_all, y_all, test_size=0.2)\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.25)\n",
    "\n",
    "print(train_x.shape, val_x.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features from document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(93636, 15202) (31212, 15202)\n  (0, 3912)\t1\n  (0, 9215)\t1\n  (0, 8789)\t1\n  (0, 8707)\t1\n  (0, 13462)\t1\n  (0, 13471)\t1\n  (0, 11807)\t1\n  (1, 13471)\t2\n  (1, 3712)\t1\n  (1, 9186)\t1\n  (1, 11236)\t1\n  (1, 13647)\t1\n  (1, 7795)\t1\n  (1, 9208)\t1\n  (1, 8222)\t1\n  (1, 2644)\t1\n  (1, 1872)\t1\n  (2, 4644)\t1\n  (2, 14594)\t1\n  (2, 7333)\t1\n  (3, 13471)\t1\n  (3, 4654)\t1\n  (3, 501)\t1\n  (3, 7652)\t1\n  (3, 6034)\t1\n  (4, 13471)\t1\n  (4, 13647)\t1\n  (4, 9208)\t2\n  (4, 1086)\t1\n  (4, 1777)\t1\n  (4, 6194)\t1\n  (4, 13272)\t1\n  (4, 603)\t1\n  (4, 12267)\t1\n  (4, 12218)\t1\n  (4, 6371)\t1\n  (4, 622)\t1\n  (4, 9272)\t1\n  (4, 7212)\t1\n  (4, 14358)\t1\n  (4, 5310)\t1\n  (4, 504)\t1\n  (4, 14398)\t1\n  (4, 14130)\t1   (0, 9208)\t1\n  (0, 11271)\t1\n  (0, 14542)\t1\n  (1, 2790)\t1\n  (2, 8209)\t1\n  (2, 10016)\t1\n  (2, 13684)\t1\n  (3, 1253)\t1\n  (3, 5803)\t1\n  (3, 6175)\t1\n  (4, 4988)\t1\n  (4, 7730)\t1\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "x_train_counts = count_vect.fit_transform(train_x)\n",
    "x_test_counts = count_vect.transform(test_x)\n",
    "\n",
    "print(x_train_counts.shape,x_test_counts.shape)\n",
    "print(x_train_counts[:5],x_test_counts[:5]) # stored as sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(93636, 15202) (31212, 15202)\n  (0, 13471)\t0.15744717193454452\n  (0, 13462)\t0.3214635921744103\n  (0, 11807)\t0.47502903085533665\n  (0, 9215)\t0.5291820062818362\n  (0, 8789)\t0.3621621708326473\n  (0, 8707)\t0.31493430684174945\n  (0, 3912)\t0.3685652118963482\n  (1, 13647)\t0.13810284551177524\n  (1, 13471)\t0.21354343692677416\n  (1, 11236)\t0.4020670464818833\n  (1, 9208)\t0.12262172931488188\n  (1, 9186)\t0.35111665318267493\n  (1, 8222)\t0.4105703108614773\n  (1, 7795)\t0.3258121887911673\n  (1, 3712)\t0.31732943589616697\n  (1, 2644)\t0.46880394844367196\n  (1, 1872)\t0.20038270037524197\n  (2, 14594)\t0.5535242806793065\n  (2, 7333)\t0.6639882823402067\n  (2, 4644)\t0.5027230167929039\n  (3, 13471)\t0.13137606960749482\n  (3, 7652)\t0.5702814395241158\n  (3, 6034)\t0.4611397609398899\n  (3, 4654)\t0.44735078856811167\n  (3, 501)\t0.49471891101571863\n  (4, 14398)\t0.2104752989856234\n  (4, 14358)\t0.18608171954649474\n  (4, 14130)\t0.2881469672641313\n  (4, 13647)\t0.10978223181707916\n  (4, 13471)\t0.08487614794914587\n  (4, 13272)\t0.2890131500288696\n  (4, 12267)\t0.2591888953373952\n  (4, 12218)\t0.3060831275595405\n  (4, 9272)\t0.3397308585847897\n  (4, 9208)\t0.1949516255595138\n  (4, 7212)\t0.13235015929205143\n  (4, 6371)\t0.2449989552462889\n  (4, 6194)\t0.17778675496935806\n  (4, 5310)\t0.14725707788168133\n  (4, 1777)\t0.292220549330812\n  (4, 1086)\t0.37746655249121286\n  (4, 622)\t0.09663728235176745\n  (4, 603)\t0.151488647549632\n  (4, 504)\t0.1731362418800051   (0, 14542)\t0.7407161914269553\n  (0, 11271)\t0.6326986969799618\n  (0, 9208)\t0.2259023740419845\n  (1, 2790)\t1.0\n  (2, 13684)\t0.46491163715501144\n  (2, 10016)\t0.7175311451507917\n  (2, 8209)\t0.5186581006563382\n  (3, 6175)\t0.4446324585464282\n  (3, 5803)\t0.6859614931824585\n  (3, 1253)\t0.575985075047827\n  (4, 7730)\t0.5335923301420415\n  (4, 4988)\t0.8457418194777805\n"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_transformer = TfidfVectorizer(analyzer='word', max_features=50000)\n",
    "tfidf_transformer.fit(train_x)\n",
    "\n",
    "x_train_tfidf_word = tfidf_transformer.transform(train_x)\n",
    "x_test_tfidf_word = tfidf_transformer.transform(test_x)\n",
    "print(x_train_tfidf_word.shape, x_test_tfidf_word.shape)\n",
    "print(x_train_tfidf_word[:5], x_test_tfidf_word[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(93636, 80000) (31212, 80000)\n"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_transformer = TfidfVectorizer(analyzer='word', ngram_range=(2,3),max_features=50000)\n",
    "tfidf_transformer.fit(train_x)\n",
    "x_train_tfidf_ngram = tfidf_transformer.transform(train_x)\n",
    "x_test_tfidf_ngram = tfidf_transformer.transform(test_x)\n",
    "\n",
    "print(x_train_tfidf_ngram.shape, x_test_tfidf_ngram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(93636, 110404)\n"
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "train_features = hstack([x_train_counts, x_train_tfidf_word, x_train_tfidf_ngram])\n",
    "test_features = hstack([x_test_counts, x_test_tfidf_word, x_test_tfidf_ngram])\n",
    "\n",
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "alpha 0.0 max_iter 100:0.5562283737024222\nalpha 0.0 max_iter 200:0.5585992566961425\nalpha 0.0 max_iter 500:0.5560361399461745\nalpha 0.0 max_iter 1000:0.5553633217993079\nalpha 0.0001 max_iter 100:0.5580866333461489\nalpha 0.0001 max_iter 200:0.5543060361399462\nalpha 0.0001 max_iter 500:0.5561002178649237\nalpha 0.0001 max_iter 1000:0.5560681789055492\nalpha 0.0002 max_iter 100:0.556164295783673\nalpha 0.0002 max_iter 200:0.553280789439959\nalpha 0.0002 max_iter 500:0.555683711393054\nalpha 0.0002 max_iter 1000:0.5553633217993079\nalpha 0.00030000000000000003 max_iter 100:0.5530565167243368\nalpha 0.00030000000000000003 max_iter 200:0.5523516596180956\nalpha 0.00030000000000000003 max_iter 500:0.5547545815711906\nalpha 0.00030000000000000003 max_iter 1000:0.5534730231962066\nalpha 0.0004 max_iter 100:0.5517108804306036\nalpha 0.0004 max_iter 200:0.5527681660899654\nalpha 0.0004 max_iter 500:0.550237088299372\nalpha 0.0004 max_iter 1000:0.5515827245931052\nalpha 0.0005 max_iter 100:0.5506856337306164\nalpha 0.0005 max_iter 200:0.5498846597462514\nalpha 0.0005 max_iter 500:0.5511021402024863\nalpha 0.0005 max_iter 1000:0.5506215558118672\nalpha 0.0006000000000000001 max_iter 100:0.5496283480712546\nalpha 0.0006000000000000001 max_iter 200:0.5492118415993849\nalpha 0.0006000000000000001 max_iter 500:0.550076893502499\nalpha 0.0006000000000000001 max_iter 1000:0.5493720363962579\nalpha 0.0007 max_iter 100:0.550557477893118\nalpha 0.0007 max_iter 200:0.5493720363962579\nalpha 0.0007 max_iter 500:0.5495322311931309\nalpha 0.0007 max_iter 1000:0.5477380494681533\nalpha 0.0008 max_iter 100:0.5489234909650135\nalpha 0.0008 max_iter 200:0.5480904780212739\nalpha 0.0008 max_iter 500:0.5471613481994105\nalpha 0.0008 max_iter 1000:0.5469370754837883\nalpha 0.0009000000000000001 max_iter 100:0.5467768806869153\nalpha 0.0009000000000000001 max_iter 200:0.5465846469306677\nalpha 0.0009000000000000001 max_iter 500:0.5478982442650263\nalpha 0.0009000000000000001 max_iter 1000:0.5467128027681661\n"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "max_iters = [100, 200, 500 ,1000]\n",
    "lr_rates = [i*1e-4 for i in range(10)]\n",
    "\n",
    "for lr_rate in lr_rates:\n",
    "    for max_iter in max_iters:\n",
    "        clf = SGDClassifier(alpha=lr_rate,loss=\"log\",early_stopping=True,eta0=0.001,learning_rate='adaptive',max_iter=max_iter)\n",
    "        clf.fit(train_features, train_y)\n",
    "        predict = clf.predict(test_features)\n",
    "        print(\"alpha {0} max_iter {1}:{2}\".format(lr_rate, max_iter,np.mean(predict == test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitbasecondab23fc3ce6234409587686fef05477388",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 利用pandas读取dataframe数据\n",
    "data_root = '/home/henry/nlp-beginner/data/'\n",
    "train_data=pd.read_csv(data_root+'train.tsv',sep='\\t')\n",
    "# test_data=pd.read_csv(data_root+'test.tsv',sep='\\t')\n",
    "pd.set_option('display.width', 900)\n",
    "x_all = train_data['Phrase']\n",
    "y_all = train_data['Sentiment']\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_all, y_all, test_size=0.2)\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.25)\n",
    "\n",
    "print(train_x.shape, val_x.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features from Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "x_train_counts = count_vect.fit_transform(train_x)\n",
    "x_test_counts = count_vect.transform(test_x)\n",
    "\n",
    "print(x_train_counts.shape,x_test_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_transformer = TfidfVectorizer(analyzer='word', max_features=50000)\n",
    "tfidf_transformer.fit(train_x)\n",
    "\n",
    "x_train_tfidf_word = tfidf_transformer.transform(train_x)\n",
    "x_test_tfidf_word = tfidf_transformer.transform(test_x)\n",
    "print(x_train_tfidf_word.shape, x_test_tfidf_word.shape)\n",
    "print(x_train_tfidf_word[:5], x_test_tfidf_word[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_transformer = TfidfVectorizer(analyzer='word', ngram_range=(2,3),max_features=50000)\n",
    "tfidf_transformer.fit(train_x)\n",
    "x_train_tfidf_ngram = tfidf_transformer.transform(train_x)\n",
    "x_test_tfidf_ngram = tfidf_transformer.transform(test_x)\n",
    "\n",
    "print(x_train_tfidf_ngram.shape, x_test_tfidf_ngram.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate Features to Form Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "train_features = hstack([x_train_counts, x_train_tfidf_word, x_train_tfidf_ngram])\n",
    "test_features = hstack([x_test_counts, x_test_tfidf_word, x_test_tfidf_ngram])\n",
    "\n",
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a SGD Classifier and Explore some Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "max_iters = [100, 200, 500 ,1000]\n",
    "lr_rates = [i*1e-4 for i in range(10)]\n",
    "\n",
    "for lr_rate in lr_rates:\n",
    "    for max_iter in max_iters:\n",
    "        clf = SGDClassifier(alpha=lr_rate,loss=\"log\",early_stopping=True,eta0=0.001,learning_rate='adaptive',max_iter=max_iter)\n",
    "        clf.fit(train_features, train_y)\n",
    "        predict = clf.predict(test_features)\n",
    "        print(\"alpha {0} max_iter {1}:{2}\".format(lr_rate, max_iter,np.mean(predict == test_y)))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitbasecondab23fc3ce6234409587686fef05477388",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
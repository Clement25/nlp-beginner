{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36564bitanaconda3conda4d2a131d00244148923b6e8eafe61e3b",
   "display_name": "Python 3.6.5 64-bit ('Anaconda3': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PhraseId  SentenceId                                             Phrase  Sentiment\n0              1           1  A series of escapades demonstrating the adage ...          1\n1              2           1  A series of escapades demonstrating the adage ...          2\n2              3           1                                           A series          2\n3              4           1                                                  A          2\n4              5           1                                             series          2\n...          ...         ...                                                ...        ...\n156055    156056        8544                                          Hearst 's          2\n156056    156057        8544                          forced avuncular chortles          1\n156057    156058        8544                                 avuncular chortles          3\n156058    156059        8544                                          avuncular          2\n156059    156060        8544                                           chortles          2\n\n[156060 rows x 4 columns]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "52"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_root = './data/'\n",
    "train_data=pd.read_csv(data_root+'train.tsv',sep='\\t')\n",
    "test_data=pd.read_csv(data_root+'test.tsv',sep='\\t')\n",
    "pd.set_option('display.width', 900)\n",
    "print(train_data)\n",
    "\n",
    "Phrases = train_data['Phrase']\n",
    "MaxSeqlen = 0\n",
    "for p in Phrases:\n",
    "    words = p.split()\n",
    "    if len(words) > MaxSeqlen:\n",
    "        MaxSeqlen = len(words)\n",
    "MaxSeqlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 0.  1.  2. ...  0.  0.  0.]\n [ 0.  1.  2. ...  0.  0.  0.]\n [ 0.  1.  0. ...  0.  0.  0.]\n ...\n [ 8.  9. 10. ...  0.  0.  0.]\n [ 8.  0.  0. ...  0.  0.  0.]\n [ 9. 10. 11. ...  0.  0.  0.]]\n(156060, 5)\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "word2id = {}\n",
    "\n",
    "BOW = np.zeros((len(Phrases),MaxSeqlen),dtype=np.float)\n",
    "for i,p in enumerate(Phrases):\n",
    "    words = p.split()\n",
    "    words_id = []\n",
    "    for word in words:\n",
    "        if word not in word2id:\n",
    "            word2id[word]=len(word2id)\n",
    "        words_id.append(word2id[word])\n",
    "    BOW[i][:len(words)] = words_id\n",
    "\n",
    "print(BOW[:20])\n",
    "labels = train_data['Sentiment']\n",
    "label_list = list(set(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "invalid number of arguments",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-a59156cc2d72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mce_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mprint_every\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Step %d, loss: %.2f\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-a59156cc2d72>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(loss, w)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(f, *varargs, **kwargs)\u001b[0m\n\u001b[0;32m    999\u001b[0m             \u001b[0mdx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiffx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1001\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"invalid number of arguments\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m     \u001b[0medge_order\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'edge_order'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: invalid number of arguments"
     ]
    }
   ],
   "source": [
    "n_iter = 10\n",
    "batch_size = 256\n",
    "n_features = MaxSeqlen\n",
    "n_class = len(label_list)\n",
    "lr = 1e-3\n",
    "print_every = 50\n",
    "\n",
    "def make_network(n_hidden=128):\n",
    "    model = dict(\n",
    "        W1=np.random.randn(MaxSeqlen, n_hidden),\n",
    "        W2=np.random.randn(n_hidden, n_class)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x)/(np.sum(np.exp(x),axis=1)[:,None])\n",
    "\n",
    "def forward(x,w):\n",
    "    h = x @ w['W1']\n",
    "    x = h @ w['W2']\n",
    "    output = softmax(x)\n",
    "    return h, output\n",
    "\n",
    "def ce_loss(probs, labels):\n",
    "    log_probs = np.log(probs)\n",
    "    return -np.sum(log_probs[:,labels])\n",
    "\n",
    "def backward(loss, h, w, err):\n",
    "    dW2 = h.T @ err\n",
    "\n",
    "model = make_network()\n",
    "step = 0\n",
    "for i in range(n_iter):\n",
    "    start_idx = 0\n",
    "    while start_idx + batch_size <= BOW.shape[0]:\n",
    "        train_data = BOW[start_idx:start_idx+batch_size]\n",
    "        train_label = labels[start_idx:start_idx+batch_size]\n",
    "        h, output = forward(train_data, model)\n",
    "        loss = ce_loss(output, train_label)\n",
    "        backward(loss, model)\n",
    "        if step%print_every == 0:\n",
    "            print(\"Step %d, loss: %.2f\", loss)\n",
    "        step += 1\n",
    "        start_idx += batch_size"
   ]
  }
 ]
}